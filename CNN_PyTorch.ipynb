{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network (CNN) in PyTorch\n",
    "Sebbene esistano alternative, come la libreria `Keras`, la strategia migliore per scrivere modelli in `PyTorch` è sviluppare sotto classi di una classe che rappresenta __moduli generici__. \n",
    "I moduli possono contenere altri moduli, permettendo di annidare elementi funzionali. Le operazioni più comuni, come layer lineari, convoluzionali o self attention etc, sono tutti moduli in PyTorch.\n",
    "\n",
    "In generale, il pattern di programmazione di un modulo consiste di due fasi: \n",
    "- Nella __prima fase__ si dichiarano i moduli necessari alla creazione del modulo corrente, viene fatto nel costruttore. Si scelgono le dimensioni dei sotto moduli e viene effettuata l'inizializzazione.\n",
    "- Nella __seconda fase__ si va a sovraccaricare il metodo `foreward()`, che, data un'istanza, ritorna un nuovo tensore risultate dalle operazioni specificate nel modulo.\n",
    "\n",
    "Le dimensioni dei layer non vengono calcolate automaticamente in PyTorch, a differenza di Keras. Quindi, per evitare errori, è utile disegnare uno __schema del modello__.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img_CNN.png\" width=\"350\">\n",
    "</div>\n",
    "\n",
    "Nella figura mostrata abbiamo 4 __blocchi convoluzionali__ tutti uguali tra loro, i quali vanno in un __flattern__ per poi proseguire in una __classification head__. \n",
    "La scelta di appiattire l'ultima feature map perchè, lavorando con galassie, l'oggetto da classificare è quasi sempre al centro. Inoltre, il __collo di bottiglia__ permetterà di ridurre il numero di pesi nella classification head. \n",
    "Nel disegno sono presenti valori numerici, rappresentano i valori delle dimensioni dei tensori in ingresso e uscita dei blocchi. La strategia dei blocchi è di raddoppiare le feature maps (primo numero della tripletta), dimezzando la dimensione (gli altri due numeri).\n",
    "\n",
    "Il __blocco__ è una sequenza di __conv 2D__, __batchnorm__, __ReLu__ e per finire __max pooling 2D__ che dimezza la dimensione. Dato che si tratta di una sequenza posso usare `nn.Sequential()` come contenitore. "
   ],
   "id": "1db62d0072edddd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T15:59:33.384875Z",
     "start_time": "2024-11-29T15:59:29.940380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "from torch import nn"
   ],
   "id": "37fefcee5aa5ff57",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:12:57.705370Z",
     "start_time": "2024-11-29T16:12:57.685270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, num_filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels,\n",
    "                        out_channels = num_filters,\n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = num_filters, # ingresso uguale a out del layer precedente\n",
    "                        out_channels = num_filters, \n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),  \n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)) # dimezza altezza e larghezza delle immagini\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "id": "37479c422a7f9ea5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Il blocco è stato definito, ora posso iniziare a costruire la classe principale.\n",
    "\n",
    "I primi 4 blocchi, quelli di colore rosso nella figura, sono raggruppati in un `Sequential()`. Da notare che il numero di filtri raddoppia ogni volt, mentre la forma delle feature map si riduce di 1/4.\n",
    "\n",
    "Il __bottleneck__ è un layer convoluzionale con kernel 1x1, che riduce il numero di feature maps a quello di partenza.\n",
    "Le feature map vengono appiattite in un vettore lungo 6272 dal __flattern__.\n",
    "\n",
    "Infine, il __multi layer perceptron__ è un layer lineare con 128 neuroni e attivazione ReLu e forma la __classification head__.\n"
   ],
   "id": "b260a43882baa38e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:09:34.120481Z",
     "start_time": "2024-11-29T16:09:34.093572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_filters, mpl_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(3, num_filters, (5, 5)), \n",
    "            Block(num_filters, num_filters*2, (3, 3)),\n",
    "            Block(num_filters*2, num_filters*4, (3, 3)),\n",
    "            Block(num_filters*4, num_filters*8, (3, 3))\n",
    "        )\n",
    "        \n",
    "        self.bottle_neck = nn.Conv2d(\n",
    "            in_channels = num_filters*8,\n",
    "            out_channels = num_filters,\n",
    "            kernel_size = (1, 1)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features = 14*14*num_filters, out_features = mpl_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classification_head = nn.Linear(in_features = mpl_size, out_features = num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = self.bottle_neck(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp(x)\n",
    "        return self.classification_head(x)"
   ],
   "id": "369d44b29b13476d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:18:47.266969Z",
     "start_time": "2024-11-29T16:18:47.005655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchsummary\n",
    "\n",
    "batch_size = 4\n",
    "input_size = 224\n",
    "num_classes = 10\n",
    "num_filters = 32\n",
    "mpl_size = 128\n",
    "\n",
    "input_tensor = torch.rand(batch_size, 3, input_size, input_size)\n",
    "\n",
    "model = SimpleCNN(num_filters, mpl_size, num_classes)\n",
    "\n",
    "torchsummary.summary(model, input_size=(3, input_size, input_size), device=\"cpu\")\n"
   ],
   "id": "16b4de90c95e2b3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]           2,432\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "              ReLU-3         [-1, 32, 224, 224]               0\n",
      "            Conv2d-4         [-1, 32, 224, 224]          25,632\n",
      "       BatchNorm2d-5         [-1, 32, 224, 224]              64\n",
      "              ReLU-6         [-1, 32, 224, 224]               0\n",
      "         MaxPool2d-7         [-1, 32, 112, 112]               0\n",
      "             Block-8         [-1, 32, 112, 112]               0\n",
      "            Conv2d-9         [-1, 64, 112, 112]          18,496\n",
      "      BatchNorm2d-10         [-1, 64, 112, 112]             128\n",
      "             ReLU-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-15           [-1, 64, 56, 56]               0\n",
      "            Block-16           [-1, 64, 56, 56]               0\n",
      "           Conv2d-17          [-1, 128, 56, 56]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-23          [-1, 128, 28, 28]               0\n",
      "            Block-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 256, 28, 28]         295,168\n",
      "      BatchNorm2d-26          [-1, 256, 28, 28]             512\n",
      "             ReLU-27          [-1, 256, 28, 28]               0\n",
      "           Conv2d-28          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-29          [-1, 256, 28, 28]             512\n",
      "             ReLU-30          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-31          [-1, 256, 14, 14]               0\n",
      "            Block-32          [-1, 256, 14, 14]               0\n",
      "           Conv2d-33           [-1, 32, 14, 14]           8,224\n",
      "          Flatten-34                 [-1, 6272]               0\n",
      "           Linear-35                  [-1, 128]         802,944\n",
      "             ReLU-36                  [-1, 128]               0\n",
      "           Linear-37                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,004,554\n",
      "Trainable params: 2,004,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 149.39\n",
      "Params size (MB): 7.65\n",
      "Estimated Total Size (MB): 157.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vediamo che il modello è stato costruito correttamente. Ora posso passare alla fase di training usando il dataset `Galaxy10`.",
   "id": "e88b1b0ad84e43f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T17:02:57.696638Z",
     "start_time": "2024-11-29T16:49:27.634536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "import numpy as np\n",
    "import tables\n",
    "\n",
    "class GalaxyDataset(Dataset):\n",
    "    def __init__(self, opts, filename, crop = True):\n",
    "        self.opts = opts\n",
    "        h5 = tables.File(filename) # apre il file HDF5\n",
    "        X = h5.root.images[:] # carica le immagini\n",
    "        y = h5.root.ans[:] # carica le etichette\n",
    "        \n",
    "        X = (X/255).astype(np.float32) # normalizza le immagini\n",
    "        self.X = torch.tensor(X.transpose(0, 3, 1, 2)) # trasforma le immagini in tensori\n",
    "        \n",
    "        if crop: \n",
    "            margin = (256 - 224) // 2 # calcola il margine\n",
    "            self.X = self.X[:,:,margin:-margin,margin:-margin] # ritaglia le immagini\n",
    "            \n",
    "        self.num_classes = len(np.unique(y)) # calcola il numero di classi\n",
    "        EYE = np.eye(self.num_classes) # crea una matrice identità\n",
    "        self.y = torch.tensor(EYE[y]) # trasforma le matrice identità in tensori\n",
    "        self.data_shape = X[0].shape # salva la forma delle immagini\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0] # restituisce il numero di esempi\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i] # restituisce l'i-esimo esempio        \n",
    "    \n",
    "class MakeDataLoaders():\n",
    "    def __init__(self, opts, data):\n",
    "        generator = torch.Generator().manual_seed(opts.seed) # inizializza il generatore di numeri casuali\n",
    "        train, test = torch.utils.data.random_split(data,\n",
    "                                                    lengths = [1-opts.test_size, opts.test_size],\n",
    "                                                    generator = generator) # divide il dataset in training e test set\n",
    "        \n",
    "        self.train = DataLoader(train, batch_size = opts.batch_size, shuffle = True) # crea il DataLoader per il training set\n",
    "        self.test = DataLoader(test, batch_size = opts.batch_size, shuffle = True) # crea il DataLoader per il test set\n",
    "        \n",
    "\n",
    "from types import SimpleNamespace\n",
    "from ipdb import launch_ipdb_on_exception\n",
    "from helpers import plot\n",
    "\n",
    "opts = SimpleNamespace()\n",
    "opts.seed = 1234\n",
    "opts.test_size = 0.2\n",
    "opts.batch_size = 128\n",
    "\n",
    "\n",
    "with launch_ipdb_on_exception():\n",
    "    data = GalaxyDataset(opts, 'Galaxy10_DECals.h5')\n",
    "    loaders = MakeDataLoaders(opts, data)\n",
    "    \n",
    "# Preparazione del modello\n",
    "num_filters = 32  # Numero di filtri iniziali\n",
    "mpl_size = 256  # Dimensione del MLP\n",
    "num_classes = data.num_classes  # Numero di classi dal dataset\n",
    "\n",
    "# Inizializza il modello\n",
    "model = SimpleCNN(num_filters=num_filters, mpl_size=mpl_size, num_classes=num_classes)\n",
    "\n",
    "# Imposta il dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Modello inviato al dispositivo: {device}\")\n",
    "\n",
    "# Funzione di perdita (accetta one-hot encoding)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Ottimizzatore\n",
    "learning_rate = 0.0002\n",
    "weight_decay = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Funzione di training\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.argmax(dim=1).to(device)  # Decodifica da one-hot a indice\n",
    "\n",
    "        optimizer.zero_grad()  # Reset dei gradienti\n",
    "\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "\n",
    "        loss = criterion(outputs, labels)  # Calcolo della perdita\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Aggiornamento dei pesi\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# Funzione di valutazione\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.argmax(dim=1).to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions += (preds == labels).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_accuracy = correct_predictions / total_samples\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "# Ciclo di training\n",
    "num_epochs = 100\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_accuracy = train_one_epoch(model, loaders.train, criterion, optimizer, device)\n",
    "    val_loss, val_accuracy = evaluate(model, loaders.test, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{num_epochs}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"  Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Salvataggio del modello\n",
    "torch.save(model.state_dict(), \"simple_cnn_galaxy10.pth\")\n",
    "print(\"Modello salvato come 'simple_cnn_galaxy10.pth'\")\n",
    "\n",
    "# Visualizzazione delle curve di perdita e accuratezza\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot delle curve di perdita\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot delle curve di accuratezza\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(train_accuracies, label=\"Training Accuracy\")\n",
    "plt.plot(val_accuracies, label=\"Validation Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "5469e404093b649d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello inviato al dispositivo: cpu\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 136\u001B[0m\n\u001B[0;32m    133\u001B[0m train_accuracies, val_accuracies \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, num_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m--> 136\u001B[0m     train_loss, train_accuracy \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    137\u001B[0m     val_loss, val_accuracy \u001B[38;5;241m=\u001B[39m evaluate(model, loaders\u001B[38;5;241m.\u001B[39mtest, criterion, device)\n\u001B[0;32m    139\u001B[0m     train_losses\u001B[38;5;241m.\u001B[39mappend(train_loss)\n",
      "Cell \u001B[1;32mIn[16], line 91\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(model, train_loader, criterion, optimizer, device)\u001B[0m\n\u001B[0;32m     87\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39margmax(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# Decodifica da one-hot a indice\u001B[39;00m\n\u001B[0;32m     89\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()  \u001B[38;5;66;03m# Reset dei gradienti\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m     93\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)  \u001B[38;5;66;03m# Calcolo della perdita\u001B[39;00m\n\u001B[0;32m     94\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# Backward pass\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[3], line 27\u001B[0m, in \u001B[0;36mSimpleCNN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 27\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mblocks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbottle_neck(x)\n\u001B[0;32m     29\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten(x)\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[6], line 21\u001B[0m, in \u001B[0;36mBlock.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 250\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 554\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Università\\DeepLearning\\EserciziLezioniDL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    538\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\n\u001B[0;32m    539\u001B[0m         F\u001B[38;5;241m.\u001B[39mpad(\n\u001B[0;32m    540\u001B[0m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    547\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups,\n\u001B[0;32m    548\u001B[0m     )\n\u001B[1;32m--> 549\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\n\u001B[0;32m    551\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9ea30bdebdcef98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
