{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Convolutional Neural Network (CNN) in PyTorch\n",
    "Sebbene esistano alternative, come la libreria `Keras`, la strategia migliore per scrivere modelli in `PyTorch` è sviluppare sotto classi di una classe che rappresenta __moduli generici__. \n",
    "I moduli possono contenere altri moduli, permettendo di annidare elementi funzionali. Le operazioni più comuni, come layer lineari, convoluzionali o self attention etc, sono tutti moduli in PyTorch.\n",
    "\n",
    "In generale, il pattern di programmazione di un modulo consiste di due fasi: \n",
    "- Nella __prima fase__ si dichiarano i moduli necessari alla creazione del modulo corrente, viene fatto nel costruttore. Si scelgono le dimensioni dei sotto moduli e viene effettuata l'inizializzazione.\n",
    "- Nella __seconda fase__ si va a sovraccaricare il metodo `foreward()`, che, data un'istanza, ritorna un nuovo tensore risultate dalle operazioni specificate nel modulo.\n",
    "\n",
    "Le dimensioni dei layer non vengono calcolate automaticamente in PyTorch, a differenza di Keras. Quindi, per evitare errori, è utile disegnare uno __schema del modello__.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"img_CNN.png\" width=\"350\">\n",
    "</div>\n",
    "\n",
    "Nella figura mostrata abbiamo 4 __blocchi convoluzionali__ tutti uguali tra loro, i quali vanno in un __flattern__ per poi proseguire in una __classification head__. \n",
    "La scelta di appiattire l'ultima feature map perchè, lavorando con galassie, l'oggetto da classificare è quasi sempre al centro. Inoltre, il __collo di bottiglia__ permetterà di ridurre il numero di pesi nella classification head. \n",
    "Nel disegno sono presenti valori numerici, rappresentano i valori delle dimensioni dei tensori in ingresso e uscita dei blocchi. La strategia dei blocchi è di raddoppiare le feature maps (primo numero della tripletta), dimezzando la dimensione (gli altri due numeri).\n",
    "\n",
    "Il __blocco__ è una sequenza di __conv 2D__, __batchnorm__, __ReLu__ e per finire __max pooling 2D__ che dimezza la dimensione. Dato che si tratta di una sequenza posso usare `nn.Sequential()` come contenitore. "
   ],
   "id": "1db62d0072edddd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T15:59:33.384875Z",
     "start_time": "2024-11-29T15:59:29.940380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch \n",
    "from torch import nn"
   ],
   "id": "37fefcee5aa5ff57",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:12:57.705370Z",
     "start_time": "2024-11-29T16:12:57.685270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, num_filters, kernel_size):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = in_channels,\n",
    "                        out_channels = num_filters,\n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),\n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = num_filters, # ingresso uguale a out del layer precedente\n",
    "                        out_channels = num_filters, \n",
    "                        kernel_size = kernel_size,\n",
    "                        padding = \"same\"),  \n",
    "            nn.BatchNorm2d(num_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = (2, 2)) # dimezza altezza e larghezza delle immagini\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ],
   "id": "37479c422a7f9ea5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Il blocco è stato definito, ora posso iniziare a costruire la classe principale.\n",
    "\n",
    "I primi 4 blocchi, quelli di colore rosso nella figura, sono raggruppati in un `Sequential()`. Da notare che il numero di filtri raddoppia ogni volt, mentre la forma delle feature map si riduce di 1/4.\n",
    "\n",
    "Il __bottleneck__ è un layer convoluzionale con kernel 1x1, che riduce il numero di feature maps a quello di partenza.\n",
    "Le feature map vengono appiattite in un vettore lungo 6272 dal __flattern__.\n",
    "\n",
    "Infine, il __multi layer perceptron__ è un layer lineare con 128 neuroni e attivazione ReLu e forma la __classification head__.\n"
   ],
   "id": "b260a43882baa38e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:09:34.120481Z",
     "start_time": "2024-11-29T16:09:34.093572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_filters, mpl_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            Block(3, num_filters, (5, 5)), \n",
    "            Block(num_filters, num_filters*2, (3, 3)),\n",
    "            Block(num_filters*2, num_filters*4, (3, 3)),\n",
    "            Block(num_filters*4, num_filters*8, (3, 3))\n",
    "        )\n",
    "        \n",
    "        self.bottle_neck = nn.Conv2d(\n",
    "            in_channels = num_filters*8,\n",
    "            out_channels = num_filters,\n",
    "            kernel_size = (1, 1)\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features = 14*14*num_filters, out_features = mpl_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classification_head = nn.Linear(in_features = mpl_size, out_features = num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        x = self.bottle_neck(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp(x)\n",
    "        return self.classification_head(x)"
   ],
   "id": "369d44b29b13476d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T16:18:47.266969Z",
     "start_time": "2024-11-29T16:18:47.005655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchsummary\n",
    "\n",
    "batch_size = 4\n",
    "input_size = 224\n",
    "num_classes = 10\n",
    "num_filters = 32\n",
    "mpl_size = 128\n",
    "\n",
    "input_tensor = torch.rand(batch_size, 3, input_size, input_size)\n",
    "\n",
    "model = SimpleCNN(num_filters, mpl_size, num_classes)\n",
    "\n",
    "torchsummary.summary(model, input_size=(3, input_size, input_size), device=\"cpu\")\n"
   ],
   "id": "16b4de90c95e2b3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]           2,432\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "              ReLU-3         [-1, 32, 224, 224]               0\n",
      "            Conv2d-4         [-1, 32, 224, 224]          25,632\n",
      "       BatchNorm2d-5         [-1, 32, 224, 224]              64\n",
      "              ReLU-6         [-1, 32, 224, 224]               0\n",
      "         MaxPool2d-7         [-1, 32, 112, 112]               0\n",
      "             Block-8         [-1, 32, 112, 112]               0\n",
      "            Conv2d-9         [-1, 64, 112, 112]          18,496\n",
      "      BatchNorm2d-10         [-1, 64, 112, 112]             128\n",
      "             ReLU-11         [-1, 64, 112, 112]               0\n",
      "           Conv2d-12         [-1, 64, 112, 112]          36,928\n",
      "      BatchNorm2d-13         [-1, 64, 112, 112]             128\n",
      "             ReLU-14         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-15           [-1, 64, 56, 56]               0\n",
      "            Block-16           [-1, 64, 56, 56]               0\n",
      "           Conv2d-17          [-1, 128, 56, 56]          73,856\n",
      "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 56, 56]         147,584\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-23          [-1, 128, 28, 28]               0\n",
      "            Block-24          [-1, 128, 28, 28]               0\n",
      "           Conv2d-25          [-1, 256, 28, 28]         295,168\n",
      "      BatchNorm2d-26          [-1, 256, 28, 28]             512\n",
      "             ReLU-27          [-1, 256, 28, 28]               0\n",
      "           Conv2d-28          [-1, 256, 28, 28]         590,080\n",
      "      BatchNorm2d-29          [-1, 256, 28, 28]             512\n",
      "             ReLU-30          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-31          [-1, 256, 14, 14]               0\n",
      "            Block-32          [-1, 256, 14, 14]               0\n",
      "           Conv2d-33           [-1, 32, 14, 14]           8,224\n",
      "          Flatten-34                 [-1, 6272]               0\n",
      "           Linear-35                  [-1, 128]         802,944\n",
      "             ReLU-36                  [-1, 128]               0\n",
      "           Linear-37                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,004,554\n",
      "Trainable params: 2,004,554\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 149.39\n",
      "Params size (MB): 7.65\n",
      "Estimated Total Size (MB): 157.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Vediamo che il modello è stato costruito correttamente. Ora posso passare alla fase di training usando il dataset `Galaxy10`.",
   "id": "e88b1b0ad84e43f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_filters = 32\n",
    "mpl_size = 256\n",
    "seed = 1234\n",
    "test_size = 0.2\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 100\n",
    "weight_decay = 0.0005\n",
    "num_classes = 10\n",
    "\n",
    "model = SimpleCNN(num_filters, mpl_size, num_classes)\n",
    "\n"
   ],
   "id": "f5791cf590808848"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
